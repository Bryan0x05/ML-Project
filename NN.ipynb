{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Modules and tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # for handling numbers\n",
    "import pandas as pd # for handling spreadsheet data\n",
    "import os # to retrive data-set files\n",
    "import cv2 # computer vision for extracting features from images\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers # machine learning module, layers for CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c:\\Users\\bryan\\Documents\\Programming\\Git\\ML-Pr...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[151, 123, 161, 136, 143, 143, 137, 144, 145, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c:\\Users\\bryan\\Documents\\Programming\\Git\\ML-Pr...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[223, 208, 204, 216, 220, 207, 193, 189, 168, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c:\\Users\\bryan\\Documents\\Programming\\Git\\ML-Pr...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[177, 177, 178, 179, 179, 180, 181, 181, 183, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c:\\Users\\bryan\\Documents\\Programming\\Git\\ML-Pr...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[108, 29, 26, 51, 56, 54, 55, 85, 143, 151, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c:\\Users\\bryan\\Documents\\Programming\\Git\\ML-Pr...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[163, 164, 165, 166, 166, 166, 166, 165, 166, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c:\\Users\\bryan\\Documents\\Programming\\Git\\ML-Pr...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[37, 30, 63, 157, 163, 167, 175, 175, 183, 186...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c:\\Users\\bryan\\Documents\\Programming\\Git\\ML-Pr...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[92, 88, 68, 88, 94, 108, 101, 121, 156, 172, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c:\\Users\\bryan\\Documents\\Programming\\Git\\ML-Pr...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[204, 199, 215, 225, 194, 162, 167, 188, 179, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c:\\Users\\bryan\\Documents\\Programming\\Git\\ML-Pr...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[99, 101, 103, 104, 107, 110, 109, 106, 111, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>c:\\Users\\bryan\\Documents\\Programming\\Git\\ML-Pr...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>[253, 253, 251, 229, 194, 184, 194, 198, 199, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image label  \\\n",
       "0  c:\\Users\\bryan\\Documents\\Programming\\Git\\ML-Pr...  REAL   \n",
       "1  c:\\Users\\bryan\\Documents\\Programming\\Git\\ML-Pr...  REAL   \n",
       "2  c:\\Users\\bryan\\Documents\\Programming\\Git\\ML-Pr...  REAL   \n",
       "3  c:\\Users\\bryan\\Documents\\Programming\\Git\\ML-Pr...  REAL   \n",
       "4  c:\\Users\\bryan\\Documents\\Programming\\Git\\ML-Pr...  REAL   \n",
       "5  c:\\Users\\bryan\\Documents\\Programming\\Git\\ML-Pr...  REAL   \n",
       "6  c:\\Users\\bryan\\Documents\\Programming\\Git\\ML-Pr...  REAL   \n",
       "7  c:\\Users\\bryan\\Documents\\Programming\\Git\\ML-Pr...  REAL   \n",
       "8  c:\\Users\\bryan\\Documents\\Programming\\Git\\ML-Pr...  REAL   \n",
       "9  c:\\Users\\bryan\\Documents\\Programming\\Git\\ML-Pr...  REAL   \n",
       "\n",
       "                                            features  \n",
       "0  [151, 123, 161, 136, 143, 143, 137, 144, 145, ...  \n",
       "1  [223, 208, 204, 216, 220, 207, 193, 189, 168, ...  \n",
       "2  [177, 177, 178, 179, 179, 180, 181, 181, 183, ...  \n",
       "3  [108, 29, 26, 51, 56, 54, 55, 85, 143, 151, 16...  \n",
       "4  [163, 164, 165, 166, 166, 166, 166, 165, 166, ...  \n",
       "5  [37, 30, 63, 157, 163, 167, 175, 175, 183, 186...  \n",
       "6  [92, 88, 68, 88, 94, 108, 101, 121, 156, 172, ...  \n",
       "7  [204, 199, 215, 225, 194, 162, 167, 188, 179, ...  \n",
       "8  [99, 101, 103, 104, 107, 110, 109, 106, 111, 1...  \n",
       "9  [253, 253, 251, 229, 194, 184, 194, 198, 199, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to load dataset into a data frame\n",
    "# Encaplsated in a function to restrict the scope of variables that will not be needed in\n",
    "# later code blocks.\n",
    "# gray scale flag, by default it's off\n",
    "# ResizeX and ResizeY, fills these to resize image to desired size, if either\n",
    "# is 0 it's assumed to be off\n",
    "\n",
    "def loadData(grayscale:bool = False, resizeX: int = 0, resizeY = 0):\n",
    "    # helper function to fill the data variables with data from images\n",
    "    def fillData(data: dict,dir: str, label:str):\n",
    "        # list of all files in dir\n",
    "        # these values are the image files\n",
    "        list = os.listdir(dir)\n",
    "        # append image paths and labels in data dictionary\n",
    "        for image in list:\n",
    "            absImagePath = os.path.join(dir,image)\n",
    "            data['image'].append(absImagePath)\n",
    "            data['label'].append(label)\n",
    "            fileImage = cv2.imread(absImagePath)\n",
    "            # image gray scale\n",
    "            if(grayscale == True):\n",
    "                fileImage = cv2.cvtColor(fileImage,cv2.COLOR_BGR2GRAY)\n",
    "            if(resizeX > 0 and resizeY > 0):\n",
    "                target_size = (resizeX,resizeY)\n",
    "                fileImage = cv2.resize(fileImage,target_size)\n",
    "            # if it's color mode, reshape into 3-tuples(RGB)\n",
    "            if(grayscale == False):\n",
    "                data['features'].append(fileImage.reshape((-1,3)))\n",
    "            # else if it's gray scale, just flatten it\n",
    "            else: data['features'].append(fileImage.flatten())\n",
    "            \n",
    "    # dictionary to temporary house the data\n",
    "    # image = image path list, label = fake or real\n",
    "    trainData = {'image':[],'label':[], 'features':[]}\n",
    "    testData = {'image':[],'label':[], 'features':[]}\n",
    "   \n",
    "    # Read Train folder & Read test folder\n",
    "    # OS module used to ensure this works on all platforms that python runs on\n",
    "    currentDir = os.getcwd() # get's current directory to later append to image filepath for abs path\n",
    "    trainDirReal = os.path.join(currentDir,\"train\",'REAL') # abs file path to real class folder in training\n",
    "    trainDirFake = os.path.join(currentDir,'train','FAKE')\n",
    "    testDirReal = os.path.join(currentDir,\"test\",'REAL')\n",
    "    testDirFake = os.path.join(currentDir,\"test\",'FAKE')  \n",
    "\n",
    "\n",
    "    # helper function read file list from each folder and append abs path and labels\n",
    "    fillData(trainData,trainDirReal,'REAL')\n",
    "    fillData(trainData,trainDirFake,'FAKE')\n",
    "    fillData(testData,testDirReal,'REAL')\n",
    "    fillData(testData,testDirFake,'FAKE')\n",
    "        \n",
    "    # converts from dictionary type to dataframe for ease of access and compadability with\n",
    "    # ML library function calls\n",
    "    return pd.DataFrame(trainData), pd.DataFrame(testData)\n",
    "# executes function, returning 2 dataframes containing train and test data of both classes\n",
    "# Train and test data are seperated into different dataframes to enforce data hygiene \n",
    "trainData,testData = loadData(grayscale=True)\n",
    "# test if data was loaded successfully by outputing first 10 entries\n",
    "trainData.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Data-preprocessing for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1024)\n",
      "(10000, 1, 1024)\n"
     ]
    }
   ],
   "source": [
    "# additional modules\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# convert string labels to numerical ints\n",
    "yTrain = LabelEncoder().fit_transform(trainData['label'])\n",
    "yTest = LabelEncoder().fit_transform(testData['label'])\n",
    "\n",
    "# turn labels into  1-hot vectors\n",
    "yTrain = to_categorical(yTrain)\n",
    "y_Test = to_categorical(yTest)\n",
    "xTrain = np.array(testData['features'].tolist())\n",
    "xTest = np.array(testData['features'].tolist())\n",
    "print(xTrain.shape)\n",
    "reshapedXTrain = xTrain.reshape(xTrain.shape[0],1,xTrain.shape[1])\n",
    "print(reshapedXTrain.shape)\n",
    "# reshape xTrain into (num_samples,1, image features) instead of (num_samples, image_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rudimentary CNN\n",
    "Made following https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65\n",
    "\n",
    "Doesn't learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/25   error=2.866859\n",
      "epoch 2/25   error=0.000000\n",
      "epoch 3/25   error=0.000000\n",
      "epoch 4/25   error=0.000000\n",
      "epoch 5/25   error=0.000000\n",
      "epoch 6/25   error=0.000000\n",
      "epoch 7/25   error=0.000000\n",
      "epoch 8/25   error=0.000000\n",
      "epoch 9/25   error=0.000000\n",
      "epoch 10/25   error=0.000000\n",
      "epoch 11/25   error=0.000000\n",
      "epoch 12/25   error=0.000000\n",
      "epoch 13/25   error=0.000000\n",
      "epoch 14/25   error=0.000000\n",
      "epoch 15/25   error=0.000000\n",
      "epoch 16/25   error=0.000000\n",
      "epoch 17/25   error=0.000000\n",
      "epoch 18/25   error=0.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 200\u001b[0m\n\u001b[0;32m    195\u001b[0m net\u001b[38;5;241m.\u001b[39muse(cat,cat_prime)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# fitting the line to data\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# these parameters were determine by repeated testing\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreshapedXTrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43myTrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m# raw softmax vectors, with probability per class of the given index \u001b[39;00m\n\u001b[0;32m    203\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mpredict(xTest)\n",
      "Cell \u001b[1;32mIn[5], line 150\u001b[0m, in \u001b[0;36mNetwork.fit\u001b[1;34m(self, x_train, y_train, epochs, learning_rate)\u001b[0m\n\u001b[0;32m    148\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_prime(y_train[j], output)\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[1;32m--> 150\u001b[0m         error \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mbackward_propagation(error, learning_rate)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# calculate average error on all samples\u001b[39;00m\n\u001b[0;32m    153\u001b[0m err \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m samples      \n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Base class (abstract)\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    # computes the output Y of a layer for a given input X\n",
    "    def forward_propagation(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # computes dE/dX for a given dE/dY (and update parameters if any)\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        raise NotImplementedError\n",
    "# inherit from base class Layer\n",
    "class FCLayer(Layer):\n",
    "    # input_size = number of input neurons\n",
    "    # output_size = number of output neurons\n",
    "    def __init__(self, input_size, output_size):\n",
    "        # random weights prevent dead nuerons instead of 0 weights.\n",
    "        self.weights = np.random.rand(input_size, output_size) - 0.5\n",
    "        self.bias = np.random.rand(1, output_size) - 0.5\n",
    "\n",
    "\n",
    "    # returns output for a given input\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        # this is Z = feature vec + weight vec  but with an additional addition weight(known as a bias)\n",
    "        self.output = np.dot(self.input, self.weights) + self.bias\n",
    "        return self.output\n",
    "\n",
    "    # computes dE/dW, dE/dB for a given output_error=dE/dY. Returns input_error=dE/dX.\n",
    "    # dE/dW -> weight gradient, dE/dB -> bias gradient.\n",
    "    # dE/dX -> dE/dY for previous layer \n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        input_error = np.dot(output_error, self.weights.T)\n",
    "        weights_error = np.dot(self.input.T, output_error)\n",
    "        # dBias = output_error.\n",
    "        # update parameters\n",
    "        self.weights -= learning_rate * weights_error\n",
    "        self.bias -= learning_rate * output_error\n",
    "        return input_error\n",
    "    # inherit from base class Layer\n",
    "class ActivationLayer(Layer):\n",
    "    # activation = activation function...\n",
    "    # activation prime = derivative of activation function\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    # returns the activated input\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = self.activation(self.input)\n",
    "        return self.output\n",
    "\n",
    "    # Returns input_error=dE/dX for a given output_error=dE/dY.\n",
    "    # learning_rate is not used because there is no \"learnable\" parameters.\n",
    "    def backward_propagation(self, output_error,learning_rate):\n",
    "        return self.activation_prime(self.input) * output_error\n",
    "# specialized softmax layer taken from 12.2 practice tutorial with minor modifications\n",
    "class SoftmaxLayer(Layer):\n",
    "    def __init__(self, input_size):\n",
    "        self.input_size = input_size\n",
    "    # forward_propagation replaced with numerically stable forward propagation\n",
    "    def forward_propagation(self, input):\n",
    "        self.input = input\n",
    "        temp = np.exp(input - np.max(input))\n",
    "        self.output = temp / np.sum(temp)\n",
    "        return self.output\n",
    "    \n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        input_error = np.zeros(output_error.shape)\n",
    "        out = np.tile(self.output.T, self.input_size)\n",
    "        return self.output * np.dot(output_error, np.identity(self.input_size) - out)\n",
    "# activaction function\n",
    "def softmax(input):\n",
    "        temp = np.exp(input - np.max(input))\n",
    "        out = temp / np.sum(temp)\n",
    "        return out\n",
    "# standalone derivative of softmax(vectorized)\n",
    "def softmax_prime(input): \n",
    "    s = input.reshape(-1,1)\n",
    "    return np.diagflat(s) - np.dot(s, s.T)\n",
    "\n",
    "# activation function \n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "# and its derivative\n",
    "def tanh_prime(x):\n",
    "    return 1-np.tanh(x)**2\n",
    "# loss function and its derivative\n",
    "\n",
    "# mse = mean square error loss function\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true-y_pred, 2))\n",
    "# derivative of mse\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2*(y_pred-y_true)/y_true.size\n",
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.loss = None\n",
    "        self.loss_prime = None\n",
    "\n",
    "    # add layer to network\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    # set loss fun & d to use\n",
    "    def use(self, loss, loss_prime):\n",
    "        self.loss = loss\n",
    "        self.loss_prime = loss_prime\n",
    "\n",
    "    # predict output for given input\n",
    "    def predict(self, input_data):\n",
    "        # sample dimension first\n",
    "        samples = len(input_data)\n",
    "        result = []\n",
    "\n",
    "        # run network over all samples\n",
    "        for i in range(samples):\n",
    "            # forward propagation\n",
    "            output = input_data[i]\n",
    "            for layer in self.layers:\n",
    "                output = layer.forward_propagation(output)\n",
    "            result.append(output)\n",
    "\n",
    "        return result\n",
    "\n",
    "    # train the network\n",
    "    def fit(self, x_train, y_train, epochs, learning_rate):\n",
    "        # sample dimension first\n",
    "        samples = len(x_train)\n",
    "        \n",
    "        # training loop\n",
    "        for i in range(epochs):\n",
    "            err = 0\n",
    "            for j in range(samples):\n",
    "                # forward propagation\n",
    "                output = x_train[j]\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forward_propagation(output)\n",
    "\n",
    "                # compute loss (for display purpose only)\n",
    "                err += self.loss(y_train[j], output)\n",
    "\n",
    "                # backward propagation\n",
    "                error = self.loss_prime(y_train[j], output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backward_propagation(error, learning_rate)\n",
    "\n",
    "            # calculate average error on all samples\n",
    "            err /= samples      \n",
    "            print('epoch %d/%d   error=%f' % (i+1, epochs, err))\n",
    "    # mean squared error & derivative\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true - y_pred, 2))\n",
    "\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2 * (y_pred - y_true) / y_pred.size\n",
    "# cat loss & derivative\n",
    "def cat(y_true,y_pred):\n",
    "    return -np.sum(y_true * np.log(y_pred + 10**-100))\n",
    "\n",
    "def cat_prime(y_true,y_pred):\n",
    "    return -y_true/(y_pred + 10**-100)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def relu_prime(x):\n",
    "    return np.array(x >= 0).astype('int')\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix,f1_score\n",
    "\n",
    "\n",
    "# network class that manages the nueral network layers\n",
    "net = Network()\n",
    "\n",
    "# input-shape 1,1024, output 1,100\n",
    "net.add(FCLayer(xTrain.shape[1],1000))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(FCLayer(1000, 500))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(FCLayer(500, 250))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(FCLayer(250, 100))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(FCLayer(100, 25))\n",
    "net.add(ActivationLayer(relu, relu_prime))\n",
    "net.add(FCLayer(25, 2))\n",
    "net.add(SoftmaxLayer(2))\n",
    "\n",
    "net.use(cat,cat_prime)\n",
    "# fitting the line to data\n",
    "# these parameters were determine by repeated testing\n",
    "\n",
    "\n",
    "net.fit(reshapedXTrain,yTrain,epochs=25,learning_rate=0.01)\n",
    "\n",
    "# raw softmax vectors, with probability per class of the given index \n",
    "raw_predictions = net.predict(xTest)\n",
    "# extract classes from predictions\n",
    "predictions = []\n",
    "for ray in raw_predictions:\n",
    "    predictions.append(np.argmax(ray))\n",
    "\n",
    "# test and score the model\n",
    "print(classification_report(y_Test, predictions))\n",
    "print('-'*55) # prints 55 dashes\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion_matrix(y_Test, predictions))\n",
    "print(f1_score(y_Test, predictions,average='micro'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras/Tensorflow CNN\n",
    "Not functional yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import Precision,Recall\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# credit to  https://www.datacamp.com/tutorial/cnn-tensorflow-python \n",
    "# used as a reference for using kerais module to build a CNN\n",
    "# Build the Keras model\n",
    "model = models.Sequential()\n",
    "# number of classes in the dataset, both training and testing set have the same classes\n",
    "numClass = len((trainData['label'].unique()))\n",
    "# convert labels to numerical ints\n",
    "xLabels = LabelEncoder().fit_transform(trainData['label'])\n",
    "yLabels = LabelEncoder().fit_transform(testData['label'])\n",
    "# convert to 1-hot vector\n",
    "xLabels = to_categorical(xLabels,numClass) \n",
    "yLabels = to_categorical(yLabels,numClass) \n",
    "\n",
    "#TODO: Dynamically adjust to grayscale, color and size.\n",
    "inputShape = (32,32,3)\n",
    "F1Size = 32\n",
    "F2Size = 64\n",
    "FShape = (3,3)\n",
    "poolShape=(2,2)\n",
    "FCNum = 128\n",
    "\n",
    "\n",
    "# Model architecture implementation\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(F1Size, FShape, activation='relu', input_shape=inputShape))\n",
    "model.add(layers.MaxPooling2D(poolShape))\n",
    "model.add(layers.Conv2D(F2Size, FShape, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(poolShape))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(FCNum, activation='relu'))\n",
    "model.add(layers.Dense(numClass, activation='softmax'))\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "\n",
    "METRICS = metrics=['accuracy',\n",
    "               \tPrecision(name='precision'),\n",
    "               \tRecall(name='recall')]\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "          \tloss='categorical_crossentropy',\n",
    "          \tmetrics = METRICS)\n",
    "\n",
    "xFeaturesTensor = tf.constant(np.vstack(trainData['features']))\n",
    "yFeaturesTensor = tf.constant(np.vstack(testData['features']))\n",
    "#TODO: Fix CNN\n",
    "# Train the model\n",
    "training_history = model.fit(xFeaturesTensor, xLabels,\n",
    "                \tepochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "                \tvalidation_data=(yFeaturesTensor, yLabels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from torch.nn import Module # neural network class\n",
    "from torch.nn import Conv2d # convolutional layer\n",
    "from torch.nn import Linear # fully connected layers\n",
    "from torch.nn import MaxPool2d # 2D max-pooling to reduce spatial dimensions of the input volume\n",
    "from torch.nn import ReLU # activication function\n",
    "from torch.nn import LogSoftmax # softmax classifier to return predicted probabilties of each class \n",
    "from torch import flatten # Flattens the output of mulit-dim volume, allows to apply fully connected layers to it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
